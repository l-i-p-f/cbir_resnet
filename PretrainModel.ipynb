{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary/Record:\n",
    "- Finetune, using SGD seems better than Adam.\n",
    "- Resnet101 is better than Resnet18, faster loss decay.\n",
    "\n",
    "ToDo:\n",
    "- Deconv inputs to size=224x224 for resnet may obtain a better result?\n",
    "- Learning rate decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general both transfer learning methods follow the same few steps:\n",
    "\n",
    "- Initialize the pretrained model\n",
    "- Reshape the final layer(s) to have the same number of outputs as the number of classes in the new dataset\n",
    "- Define for the optimization algorithm which parameters we want to update during training\n",
    "- Run the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  0.4.1\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"/data1/lipf/\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 100\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 512\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Validation Code\n",
    "\n",
    "Training and validation. \n",
    "\n",
    "Input : a PyTorch model, a dictionary of dataloaders, a loss function, an optimizer, a specified number of epochs to train and validate for, and a boolean flag for when the model is an Inception model. \n",
    "\n",
    "The is_inception flag is used to accomodate the Inception v3 model. \n",
    "\n",
    "The function trains for the specified number of epochs and **after each epoch runs a full validation step**. It also keeps track of the best performing model (in terms of validation accuracy), and at the end of training returns the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            iters = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                iters += inputs.size(0)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # torch.max(a,1) 返回每一行中最大值的那个元素，且返回其索引，１表示行\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # _, preds = torch.topk(outputs, 5)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                # 通过.item() 从0维张量中获得 python number.\n",
    "                # 如果loss不转为　python number　再累加，内存消耗会一直在增加。因为0维张量会增加梯度的计算历史\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                # 转置，然后扩展\n",
    "                # running_corrects += torch.sum(preds == labels.data.view(1,-1).t().expand_as(preds))\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Set Model Parameters’ .requires_grad attribute\n",
    "\n",
    "This helper function sets the .requires_grad attribute of the parameters in the model to False when we are feature extracting. By default, when we load a pretrained model all of the parameters have .requires_grad=True, which is fine if we are training from scratch or finetuning. \n",
    "\n",
    "However, if we are feature extracting and only want to compute gradients for the newly initialized layer then we want all of the other parameters to not require gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE AND RESHAPE THE NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When feature extracting, we only want to update the parameters of the last layer, or in other words, we only want to update the parameters for the layer(s) we are reshaping. Therefore, we do not need to compute the gradients of the parameters that we are not changing, so for efficiency we set the .requires_grad attribute to False. This is important because by default, this attribute is set to True. Then, when we initialize the new layer and by default the new parameters have .requires_grad=True so only the new layer’s parameters will be updated. When we are finetuning we can leave all of the .required_grad’s set to the default of True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, use_pretrained=True, is_feature_extracting=False):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet101\n",
    "        \"\"\"\n",
    "        model = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, is_feature_extracting)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.avgpool = nn.AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 32    \n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model_t, input_size = initialize_model(model_name, num_classes, use_pretrained=True, is_feature_extracting=False)\n",
    "# Send the model to GPU\n",
    "model_t = model_t.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(is_train='train', cuda=True, batch_size=512, shuffle=True):\n",
    "        if is_train == 'train':\n",
    "            trans = [transforms.RandomHorizontalFlip(),\n",
    "                     transforms.RandomCrop(32, padding=4),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "            trans = transforms.Compose(trans)\n",
    "            data_set = datasets.CIFAR100(root=data_dir, train=True, transform=trans)\n",
    "        else:\n",
    "            trans = [transforms.ToTensor(),\n",
    "                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "            trans = transforms.Compose(trans)\n",
    "            data_set = datasets.CIFAR100(data_dir, train=False, transform=trans)\n",
    "\n",
    "        return data_set\n",
    "\n",
    "dataset = {}\n",
    "for phase in ['train', 'val']:\n",
    "    dataset[phase] = dataLoader(phase)\n",
    "\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(dataset[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE THE OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "def param2update(model, is_feature_extract=False):\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if is_feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.0.conv3.weight\n",
      "\t layer1.0.bn3.weight\n",
      "\t layer1.0.bn3.bias\n",
      "\t layer1.0.downsample.0.weight\n",
      "\t layer1.0.downsample.1.weight\n",
      "\t layer1.0.downsample.1.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.1.conv3.weight\n",
      "\t layer1.1.bn3.weight\n",
      "\t layer1.1.bn3.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer1.2.conv3.weight\n",
      "\t layer1.2.bn3.weight\n",
      "\t layer1.2.bn3.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.conv3.weight\n",
      "\t layer2.0.bn3.weight\n",
      "\t layer2.0.bn3.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.1.conv3.weight\n",
      "\t layer2.1.bn3.weight\n",
      "\t layer2.1.bn3.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.2.conv3.weight\n",
      "\t layer2.2.bn3.weight\n",
      "\t layer2.2.bn3.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer2.3.conv3.weight\n",
      "\t layer2.3.bn3.weight\n",
      "\t layer2.3.bn3.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.conv3.weight\n",
      "\t layer3.0.bn3.weight\n",
      "\t layer3.0.bn3.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.1.conv3.weight\n",
      "\t layer3.1.bn3.weight\n",
      "\t layer3.1.bn3.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.2.conv3.weight\n",
      "\t layer3.2.bn3.weight\n",
      "\t layer3.2.bn3.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.3.conv3.weight\n",
      "\t layer3.3.bn3.weight\n",
      "\t layer3.3.bn3.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.4.conv3.weight\n",
      "\t layer3.4.bn3.weight\n",
      "\t layer3.4.bn3.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer3.5.conv3.weight\n",
      "\t layer3.5.bn3.weight\n",
      "\t layer3.5.bn3.bias\n",
      "\t layer3.6.conv1.weight\n",
      "\t layer3.6.bn1.weight\n",
      "\t layer3.6.bn1.bias\n",
      "\t layer3.6.conv2.weight\n",
      "\t layer3.6.bn2.weight\n",
      "\t layer3.6.bn2.bias\n",
      "\t layer3.6.conv3.weight\n",
      "\t layer3.6.bn3.weight\n",
      "\t layer3.6.bn3.bias\n",
      "\t layer3.7.conv1.weight\n",
      "\t layer3.7.bn1.weight\n",
      "\t layer3.7.bn1.bias\n",
      "\t layer3.7.conv2.weight\n",
      "\t layer3.7.bn2.weight\n",
      "\t layer3.7.bn2.bias\n",
      "\t layer3.7.conv3.weight\n",
      "\t layer3.7.bn3.weight\n",
      "\t layer3.7.bn3.bias\n",
      "\t layer3.8.conv1.weight\n",
      "\t layer3.8.bn1.weight\n",
      "\t layer3.8.bn1.bias\n",
      "\t layer3.8.conv2.weight\n",
      "\t layer3.8.bn2.weight\n",
      "\t layer3.8.bn2.bias\n",
      "\t layer3.8.conv3.weight\n",
      "\t layer3.8.bn3.weight\n",
      "\t layer3.8.bn3.bias\n",
      "\t layer3.9.conv1.weight\n",
      "\t layer3.9.bn1.weight\n",
      "\t layer3.9.bn1.bias\n",
      "\t layer3.9.conv2.weight\n",
      "\t layer3.9.bn2.weight\n",
      "\t layer3.9.bn2.bias\n",
      "\t layer3.9.conv3.weight\n",
      "\t layer3.9.bn3.weight\n",
      "\t layer3.9.bn3.bias\n",
      "\t layer3.10.conv1.weight\n",
      "\t layer3.10.bn1.weight\n",
      "\t layer3.10.bn1.bias\n",
      "\t layer3.10.conv2.weight\n",
      "\t layer3.10.bn2.weight\n",
      "\t layer3.10.bn2.bias\n",
      "\t layer3.10.conv3.weight\n",
      "\t layer3.10.bn3.weight\n",
      "\t layer3.10.bn3.bias\n",
      "\t layer3.11.conv1.weight\n",
      "\t layer3.11.bn1.weight\n",
      "\t layer3.11.bn1.bias\n",
      "\t layer3.11.conv2.weight\n",
      "\t layer3.11.bn2.weight\n",
      "\t layer3.11.bn2.bias\n",
      "\t layer3.11.conv3.weight\n",
      "\t layer3.11.bn3.weight\n",
      "\t layer3.11.bn3.bias\n",
      "\t layer3.12.conv1.weight\n",
      "\t layer3.12.bn1.weight\n",
      "\t layer3.12.bn1.bias\n",
      "\t layer3.12.conv2.weight\n",
      "\t layer3.12.bn2.weight\n",
      "\t layer3.12.bn2.bias\n",
      "\t layer3.12.conv3.weight\n",
      "\t layer3.12.bn3.weight\n",
      "\t layer3.12.bn3.bias\n",
      "\t layer3.13.conv1.weight\n",
      "\t layer3.13.bn1.weight\n",
      "\t layer3.13.bn1.bias\n",
      "\t layer3.13.conv2.weight\n",
      "\t layer3.13.bn2.weight\n",
      "\t layer3.13.bn2.bias\n",
      "\t layer3.13.conv3.weight\n",
      "\t layer3.13.bn3.weight\n",
      "\t layer3.13.bn3.bias\n",
      "\t layer3.14.conv1.weight\n",
      "\t layer3.14.bn1.weight\n",
      "\t layer3.14.bn1.bias\n",
      "\t layer3.14.conv2.weight\n",
      "\t layer3.14.bn2.weight\n",
      "\t layer3.14.bn2.bias\n",
      "\t layer3.14.conv3.weight\n",
      "\t layer3.14.bn3.weight\n",
      "\t layer3.14.bn3.bias\n",
      "\t layer3.15.conv1.weight\n",
      "\t layer3.15.bn1.weight\n",
      "\t layer3.15.bn1.bias\n",
      "\t layer3.15.conv2.weight\n",
      "\t layer3.15.bn2.weight\n",
      "\t layer3.15.bn2.bias\n",
      "\t layer3.15.conv3.weight\n",
      "\t layer3.15.bn3.weight\n",
      "\t layer3.15.bn3.bias\n",
      "\t layer3.16.conv1.weight\n",
      "\t layer3.16.bn1.weight\n",
      "\t layer3.16.bn1.bias\n",
      "\t layer3.16.conv2.weight\n",
      "\t layer3.16.bn2.weight\n",
      "\t layer3.16.bn2.bias\n",
      "\t layer3.16.conv3.weight\n",
      "\t layer3.16.bn3.weight\n",
      "\t layer3.16.bn3.bias\n",
      "\t layer3.17.conv1.weight\n",
      "\t layer3.17.bn1.weight\n",
      "\t layer3.17.bn1.bias\n",
      "\t layer3.17.conv2.weight\n",
      "\t layer3.17.bn2.weight\n",
      "\t layer3.17.bn2.bias\n",
      "\t layer3.17.conv3.weight\n",
      "\t layer3.17.bn3.weight\n",
      "\t layer3.17.bn3.bias\n",
      "\t layer3.18.conv1.weight\n",
      "\t layer3.18.bn1.weight\n",
      "\t layer3.18.bn1.bias\n",
      "\t layer3.18.conv2.weight\n",
      "\t layer3.18.bn2.weight\n",
      "\t layer3.18.bn2.bias\n",
      "\t layer3.18.conv3.weight\n",
      "\t layer3.18.bn3.weight\n",
      "\t layer3.18.bn3.bias\n",
      "\t layer3.19.conv1.weight\n",
      "\t layer3.19.bn1.weight\n",
      "\t layer3.19.bn1.bias\n",
      "\t layer3.19.conv2.weight\n",
      "\t layer3.19.bn2.weight\n",
      "\t layer3.19.bn2.bias\n",
      "\t layer3.19.conv3.weight\n",
      "\t layer3.19.bn3.weight\n",
      "\t layer3.19.bn3.bias\n",
      "\t layer3.20.conv1.weight\n",
      "\t layer3.20.bn1.weight\n",
      "\t layer3.20.bn1.bias\n",
      "\t layer3.20.conv2.weight\n",
      "\t layer3.20.bn2.weight\n",
      "\t layer3.20.bn2.bias\n",
      "\t layer3.20.conv3.weight\n",
      "\t layer3.20.bn3.weight\n",
      "\t layer3.20.bn3.bias\n",
      "\t layer3.21.conv1.weight\n",
      "\t layer3.21.bn1.weight\n",
      "\t layer3.21.bn1.bias\n",
      "\t layer3.21.conv2.weight\n",
      "\t layer3.21.bn2.weight\n",
      "\t layer3.21.bn2.bias\n",
      "\t layer3.21.conv3.weight\n",
      "\t layer3.21.bn3.weight\n",
      "\t layer3.21.bn3.bias\n",
      "\t layer3.22.conv1.weight\n",
      "\t layer3.22.bn1.weight\n",
      "\t layer3.22.bn1.bias\n",
      "\t layer3.22.conv2.weight\n",
      "\t layer3.22.bn2.weight\n",
      "\t layer3.22.bn2.bias\n",
      "\t layer3.22.conv3.weight\n",
      "\t layer3.22.bn3.weight\n",
      "\t layer3.22.bn3.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.conv3.weight\n",
      "\t layer4.0.bn3.weight\n",
      "\t layer4.0.bn3.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.1.conv3.weight\n",
      "\t layer4.1.bn3.weight\n",
      "\t layer4.1.bn3.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t layer4.2.conv3.weight\n",
      "\t layer4.2.bn3.weight\n",
      "\t layer4.2.bn3.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = param2update(model_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN TRAINING AND VALIDATION STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_t = optim.Adam(params_to_update, lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 2.8449 Acc: 0.2878\n",
      "val Loss: 2.2750 Acc: 0.4071\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.9888 Acc: 0.4586\n",
      "val Loss: 1.8579 Acc: 0.5018\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.7142 Acc: 0.5231\n",
      "val Loss: 1.9575 Acc: 0.5014\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.6056 Acc: 0.5479\n",
      "val Loss: 1.9720 Acc: 0.4906\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.4738 Acc: 0.5818\n",
      "val Loss: 2.0003 Acc: 0.5274\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.4511 Acc: 0.5897\n",
      "val Loss: 13.2432 Acc: 0.4528\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.5159 Acc: 0.5816\n",
      "val Loss: 1.7009 Acc: 0.5472\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.6855 Acc: 0.5457\n",
      "val Loss: 4.7685 Acc: 0.1436\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.9454 Acc: 0.4738\n",
      "val Loss: 1.7634 Acc: 0.5249\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.4522 Acc: 0.5870\n",
      "val Loss: 3.8643 Acc: 0.5060\n",
      "\n",
      "Training complete in 4m 55s\n",
      "Best val Acc: 0.547200\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_t, hist = train_model(model_t, dataloaders_dict, criterion, optimizer_t, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune model - Fix backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, use_pretrained=True, is_feature_extracting=True)\n",
    "model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update_ft = param2update(model_ft, is_feature_extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 4.5639 Acc: 0.0303\n",
      "val Loss: 4.4881 Acc: 0.0600\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 4.3063 Acc: 0.0878\n",
      "val Loss: 4.2986 Acc: 0.1022\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 4.1195 Acc: 0.1300\n",
      "val Loss: 4.1395 Acc: 0.1285\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 3.9801 Acc: 0.1520\n",
      "val Loss: 4.0559 Acc: 0.1495\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 3.8674 Acc: 0.1734\n",
      "val Loss: 4.0299 Acc: 0.1584\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 3.7762 Acc: 0.1852\n",
      "val Loss: 3.9252 Acc: 0.1706\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 3.6987 Acc: 0.1945\n",
      "val Loss: 3.8413 Acc: 0.1758\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 3.6408 Acc: 0.2016\n",
      "val Loss: 3.7986 Acc: 0.1810\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 3.5886 Acc: 0.2062\n",
      "val Loss: 3.8332 Acc: 0.1834\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 3.5331 Acc: 0.2123\n",
      "val Loss: 3.7316 Acc: 0.1896\n",
      "\n",
      "Training complete in 1m 50s\n",
      "Best val Acc: 0.189600\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update_ft, lr=0.001, momentum=0.9)\n",
    "\n",
    "model_ft, hist_ft = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune model - relearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backbone层参数只需微调，故学习率可以小一些。\n",
    "\n",
    "classifier层参数为重新学习，学习率大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(ResNet, self).__init__()\n",
    "        net = models.resnet101(pretrained=True)\n",
    "        self.backbone = nn.Sequential(\n",
    "            net.conv1,\n",
    "            net.bn1,\n",
    "            net.relu,\n",
    "            net.maxpool,\n",
    "            net.layer1,\n",
    "            net.layer2,\n",
    "            net.layer3,\n",
    "            net.layer4,\n",
    "            nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "        num_ftrs = net.fc.in_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_config_optim(self, lr, lrp):\n",
    "        return [{ 'params': self.backbone.parameters(), 'lr': lr*lrp},\n",
    "                {'params': self.classifier.parameters()}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果学习率设置不合理会报错：\n",
    "\n",
    "    OSError: [Errno 9] Bad file descriptor\n",
    "    \n",
    "原因？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 3.0201 Acc: 0.2692\n",
      "val Loss: 2.1843 Acc: 0.4256\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.9208 Acc: 0.4733\n",
      "val Loss: 1.8232 Acc: 0.5041\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.5994 Acc: 0.5508\n",
      "val Loss: 1.7521 Acc: 0.5335\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.3737 Acc: 0.6054\n",
      "val Loss: 1.6099 Acc: 0.5557\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.2102 Acc: 0.6466\n",
      "val Loss: 1.6261 Acc: 0.5616\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.0643 Acc: 0.6855\n",
      "val Loss: 1.5898 Acc: 0.5759\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.9387 Acc: 0.7196\n",
      "val Loss: 1.6225 Acc: 0.5767\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.8457 Acc: 0.7415\n",
      "val Loss: 1.6252 Acc: 0.5870\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.7751\n",
      "val Loss: 1.6437 Acc: 0.5869\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.7982\n",
      "val Loss: 1.7431 Acc: 0.5860\n",
      "\n",
      "Training complete in 4m 44s\n",
      "Best val Acc: 0.587000\n"
     ]
    }
   ],
   "source": [
    "model_ftr = ResNet(num_classes)\n",
    "model_ftr.to(device)\n",
    "\n",
    "lr = 0.05\n",
    "# optimizer_ft = optim.Adam(model_ft.get_config_optim(lr, 0.1), lr=lr, betas=(0.9, 0.999))\n",
    "optimizer_ftr = optim.SGD(model_ftr.get_config_optim(lr, 0.1), lr=lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ftr, hist_ftr = train_model(model_ftr, dataloaders_dict, criterion, optimizer_ftr, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以下代码功能等同于上面两个步骤\n",
    "\n",
    "# model_ftr = models.resnet101(pretrained=True)\n",
    "# num_ftrs = model_ftr.fc.in_features\n",
    "# model_ftr.avgpool = nn.AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
    "# model_ftr.fc = nn.Linear(num_ftrs, num_classes)\n",
    "# model_ftr.to(device)\n",
    "\n",
    "# ignored_params = list(map(id, model_ftr.fc.parameters()))\n",
    "# base_params = filter(lambda p:id(p) not in ignored_params, model_ftr.parameters())\n",
    "\n",
    "# params_list = [{'params':base_params, 'lr':0.001}]\n",
    "# params_list.append({'params':model_ftr.fc.parameters(), 'lr':0.01})\n",
    "\n",
    "# optimizer_ftr = optim.SGD(params_list, lr=0.001, momentum=0.9)\n",
    "\n",
    "# model_ftr, hist_ftr = train_model(model_ftr, dataloaders_dict, criterion, optimizer_ftr, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotacc(hist, hist_ft, hist_ftr, num_epochs):\n",
    "    t_hist = []\n",
    "    ft_hist = []\n",
    "    ftr_hist = []\n",
    "    \n",
    "    t_hist = [h.cpu().numpy() for h in hist]\n",
    "    ft_hist = [h.cpu().numpy() for h in hist_ft]\n",
    "    ftr_hist = [h.cpu().numpy() for h in hist_ftr]\n",
    "\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.plot(range(1,num_epochs+1),t_hist,label=\"Relearn\")\n",
    "    plt.plot(range(1,num_epochs+1),ft_hist,label=\"Finetune-fix-backbone\")\n",
    "    plt.plot(range(1,num_epochs+1),ftr_hist,label=\"Finetune-relearn\")\n",
    "    plt.ylim((0,1.))\n",
    "    plt.xticks(np.arange(1, num_epochs+1, 2.0))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUJAkDQwFSdLgE1vew/jbUiniAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa59c033c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotacc(hist, hist_ft, hist_ftr, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save parameters\n",
    "def save_model(save_path):\n",
    "    torch.save(model_ftr.cpu().state_dict(), save_path)\n",
    "    \n",
    "save_path = './model_ftr_587.pth'\n",
    "save_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
